{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "03_cnn(1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTEzoMx6CasV"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhmPj1VVCfWb"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovTGnGws2vzf"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Cat vs. Dog Image Classification\n",
        "## Exercise 3: Feature Extraction and Fine-Tuning\n",
        "**_Estimated completion time: 30 minutes_**\n",
        "\n",
        "In Exercise 1, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. With the addition of data augmentation and dropout in Exercise 2, we were able to increase accuracy to about 80%. That seems decent, but 20% is still too high of an error rate. Maybe we just don't have enough training data available to properly solve the problem. What other approaches can we try?\n",
        "\n",
        "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, **feature extraction** and **fine tuning**, and use them to improve the accuracy of our cat vs. dog classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI5rmt4UBwXs"
      },
      "source": [
        "## Feature Extraction Using a Pretrained Model\n",
        "\n",
        "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
        "\n",
        "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
        "\n",
        "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
        "\n",
        "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xJZ5glPPCRz"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaXLMtYiF0t9"
      },
      "source": [
        "Now let's download the weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMrbllgAFipZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e73c1e8-e79a-4f3f-ccef-b47b4dbdb6a2"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-23 15:17:13--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 108.177.15.128, 173.194.76.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  53.3MB/s    in 1.6s    \n",
            "\n",
            "2021-04-23 15:17:15 (53.3 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRiGBfOF8rq"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "pre_trained_model.load_weights(local_weights_file)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcYZPBS3bTAj"
      },
      "source": [
        "By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFxrqTuJee5m"
      },
      "source": [
        "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a38rB3lyedcB"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGBGDiOAepnO"
      },
      "source": [
        "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj4rXshqbQlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b83da6f-f02e-424c-bd01-82fdd795c966"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxHk6XQLeUWh"
      },
      "source": [
        "Now let's stick a fully connected classifier on top of `last_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMXb913pbvFg"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "model = Model(pre_trained_model.input, x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.0001),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ECjowwV5Ug"
      },
      "source": [
        "For examples and data preprocessing, let's use the same files and `train_generator` as we did in Exercise 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl-IqOTjZVw_"
      },
      "source": [
        "**NOTE:** The 2,000 images used in this exercise are excerpted from the [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5032ffd-cb43-4633-ec11-7962c13dbcf4"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \\\n",
        "   /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-23 15:19:10--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.206.128, 64.233.167.128, 64.233.166.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.206.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  40.1MB/s    in 1.6s    \n",
            "\n",
            "2021-04-23 15:19:12 (40.1 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl9XXARuV_eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a35d95e-33e0-429a-afd3-23c190fd2366"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "train_cat_fnames = os.listdir(train_cats_dir)\n",
        "train_dog_fnames = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEC1AL7iVRLz"
      },
      "source": [
        "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 validation images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edaf0300-4fe2-43c4-9ce9-52a5ea3c07ff"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=10,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 - 57s - loss: 0.3361 - acc: 0.8630 - val_loss: 0.1101 - val_acc: 0.9570\n",
            "Epoch 2/10\n",
            "100/100 - 22s - loss: 0.2207 - acc: 0.9095 - val_loss: 0.1311 - val_acc: 0.9550\n",
            "Epoch 3/10\n",
            "100/100 - 23s - loss: 0.2195 - acc: 0.9175 - val_loss: 0.1410 - val_acc: 0.9560\n",
            "Epoch 4/10\n",
            "100/100 - 22s - loss: 0.2018 - acc: 0.9260 - val_loss: 0.1321 - val_acc: 0.9600\n",
            "Epoch 5/10\n",
            "100/100 - 22s - loss: 0.2020 - acc: 0.9280 - val_loss: 0.1155 - val_acc: 0.9590\n",
            "Epoch 6/10\n",
            "100/100 - 22s - loss: 0.1765 - acc: 0.9325 - val_loss: 0.1208 - val_acc: 0.9670\n",
            "Epoch 7/10\n",
            "100/100 - 22s - loss: 0.1820 - acc: 0.9330 - val_loss: 0.1117 - val_acc: 0.9700\n",
            "Epoch 8/10\n",
            "100/100 - 22s - loss: 0.1729 - acc: 0.9410 - val_loss: 0.1104 - val_acc: 0.9680\n",
            "Epoch 9/10\n",
            "100/100 - 22s - loss: 0.1783 - acc: 0.9430 - val_loss: 0.1163 - val_acc: 0.9700\n",
            "Epoch 10/10\n",
            "100/100 - 23s - loss: 0.1592 - acc: 0.9485 - val_loss: 0.1074 - val_acc: 0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8hwTr0e55BQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2b5982-2ddf-4134-bb8d-50a2208a4244"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRjyAkE62aOG"
      },
      "source": [
        "You can see that we reach a validation accuracy of 88–90% very quickly. This is much better than the small model we trained from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt15y6IS2pBo"
      },
      "source": [
        "## Further Improving Accuracy with Fine-Tuning\n",
        "\n",
        "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
        "\n",
        "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
        "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
        "\n",
        "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l_J4S0Z2rgg"
      },
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "unfreeze = False\n",
        "\n",
        "# Unfreeze all models after \"mixed6\"\n",
        "for layer in pre_trained_model.layers:\n",
        "  if unfreeze:\n",
        "    layer.trainable = True\n",
        "  if layer.name == 'mixed6':\n",
        "    unfreeze = True\n",
        "\n",
        "# As an optimizer, here we will use SGD \n",
        "# with a very low learning rate (0.00001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=SGD(\n",
        "                  lr=0.00001, \n",
        "                  momentum=0.9),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE37ARlqY9da"
      },
      "source": [
        "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 validation images. (This may take 15-20 minutes to run.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_GgDGG4Y_hJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998e1501-181c-44b4-e161-f7d2809b7827"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=50,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,\n",
        "      verbose=2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "100/100 - 28s - loss: 0.1861 - acc: 0.9235 - val_loss: 0.0962 - val_acc: 0.9690\n",
            "Epoch 2/50\n",
            "100/100 - 22s - loss: 0.1637 - acc: 0.9305 - val_loss: 0.1058 - val_acc: 0.9600\n",
            "Epoch 3/50\n",
            "100/100 - 23s - loss: 0.1931 - acc: 0.9230 - val_loss: 0.1098 - val_acc: 0.9560\n",
            "Epoch 4/50\n",
            "100/100 - 22s - loss: 0.1694 - acc: 0.9335 - val_loss: 0.1110 - val_acc: 0.9570\n",
            "Epoch 5/50\n",
            "100/100 - 22s - loss: 0.1714 - acc: 0.9270 - val_loss: 0.1119 - val_acc: 0.9590\n",
            "Epoch 6/50\n",
            "100/100 - 22s - loss: 0.1713 - acc: 0.9280 - val_loss: 0.1119 - val_acc: 0.9600\n",
            "Epoch 7/50\n",
            "100/100 - 22s - loss: 0.1606 - acc: 0.9280 - val_loss: 0.1114 - val_acc: 0.9600\n",
            "Epoch 8/50\n",
            "100/100 - 22s - loss: 0.1731 - acc: 0.9310 - val_loss: 0.1113 - val_acc: 0.9600\n",
            "Epoch 9/50\n",
            "100/100 - 22s - loss: 0.1626 - acc: 0.9330 - val_loss: 0.1105 - val_acc: 0.9600\n",
            "Epoch 10/50\n",
            "100/100 - 22s - loss: 0.1568 - acc: 0.9375 - val_loss: 0.1108 - val_acc: 0.9600\n",
            "Epoch 11/50\n",
            "100/100 - 22s - loss: 0.1652 - acc: 0.9295 - val_loss: 0.1105 - val_acc: 0.9600\n",
            "Epoch 12/50\n",
            "100/100 - 23s - loss: 0.1731 - acc: 0.9310 - val_loss: 0.1100 - val_acc: 0.9600\n",
            "Epoch 13/50\n",
            "100/100 - 22s - loss: 0.1721 - acc: 0.9275 - val_loss: 0.1095 - val_acc: 0.9600\n",
            "Epoch 14/50\n",
            "100/100 - 22s - loss: 0.1414 - acc: 0.9350 - val_loss: 0.1101 - val_acc: 0.9590\n",
            "Epoch 15/50\n",
            "100/100 - 22s - loss: 0.1577 - acc: 0.9370 - val_loss: 0.1100 - val_acc: 0.9600\n",
            "Epoch 16/50\n",
            "100/100 - 22s - loss: 0.1530 - acc: 0.9420 - val_loss: 0.1100 - val_acc: 0.9600\n",
            "Epoch 17/50\n",
            "100/100 - 22s - loss: 0.1658 - acc: 0.9290 - val_loss: 0.1098 - val_acc: 0.9600\n",
            "Epoch 18/50\n",
            "100/100 - 22s - loss: 0.1530 - acc: 0.9350 - val_loss: 0.1093 - val_acc: 0.9600\n",
            "Epoch 19/50\n",
            "100/100 - 22s - loss: 0.1612 - acc: 0.9295 - val_loss: 0.1089 - val_acc: 0.9580\n",
            "Epoch 20/50\n",
            "100/100 - 22s - loss: 0.1675 - acc: 0.9355 - val_loss: 0.1083 - val_acc: 0.9590\n",
            "Epoch 21/50\n",
            "100/100 - 22s - loss: 0.1775 - acc: 0.9285 - val_loss: 0.1084 - val_acc: 0.9580\n",
            "Epoch 22/50\n",
            "100/100 - 22s - loss: 0.1661 - acc: 0.9285 - val_loss: 0.1083 - val_acc: 0.9590\n",
            "Epoch 23/50\n",
            "100/100 - 22s - loss: 0.1634 - acc: 0.9330 - val_loss: 0.1074 - val_acc: 0.9590\n",
            "Epoch 24/50\n",
            "100/100 - 22s - loss: 0.1672 - acc: 0.9335 - val_loss: 0.1073 - val_acc: 0.9580\n",
            "Epoch 25/50\n",
            "100/100 - 22s - loss: 0.1555 - acc: 0.9410 - val_loss: 0.1071 - val_acc: 0.9590\n",
            "Epoch 26/50\n",
            "100/100 - 23s - loss: 0.1458 - acc: 0.9445 - val_loss: 0.1071 - val_acc: 0.9590\n",
            "Epoch 27/50\n",
            "100/100 - 21s - loss: 0.1398 - acc: 0.9465 - val_loss: 0.1066 - val_acc: 0.9590\n",
            "Epoch 28/50\n",
            "100/100 - 22s - loss: 0.1512 - acc: 0.9375 - val_loss: 0.1068 - val_acc: 0.9590\n",
            "Epoch 29/50\n",
            "100/100 - 22s - loss: 0.1658 - acc: 0.9320 - val_loss: 0.1064 - val_acc: 0.9600\n",
            "Epoch 30/50\n",
            "100/100 - 22s - loss: 0.1507 - acc: 0.9360 - val_loss: 0.1064 - val_acc: 0.9610\n",
            "Epoch 31/50\n",
            "100/100 - 22s - loss: 0.1495 - acc: 0.9365 - val_loss: 0.1065 - val_acc: 0.9600\n",
            "Epoch 32/50\n",
            "100/100 - 22s - loss: 0.1636 - acc: 0.9325 - val_loss: 0.1062 - val_acc: 0.9600\n",
            "Epoch 33/50\n",
            "100/100 - 23s - loss: 0.1456 - acc: 0.9450 - val_loss: 0.1056 - val_acc: 0.9600\n",
            "Epoch 34/50\n",
            "100/100 - 22s - loss: 0.1458 - acc: 0.9415 - val_loss: 0.1058 - val_acc: 0.9600\n",
            "Epoch 35/50\n",
            "100/100 - 22s - loss: 0.1571 - acc: 0.9345 - val_loss: 0.1052 - val_acc: 0.9600\n",
            "Epoch 36/50\n",
            "100/100 - 22s - loss: 0.1510 - acc: 0.9430 - val_loss: 0.1050 - val_acc: 0.9590\n",
            "Epoch 37/50\n",
            "100/100 - 22s - loss: 0.1484 - acc: 0.9430 - val_loss: 0.1048 - val_acc: 0.9590\n",
            "Epoch 38/50\n",
            "100/100 - 22s - loss: 0.1476 - acc: 0.9420 - val_loss: 0.1047 - val_acc: 0.9590\n",
            "Epoch 39/50\n",
            "100/100 - 22s - loss: 0.1600 - acc: 0.9405 - val_loss: 0.1044 - val_acc: 0.9600\n",
            "Epoch 40/50\n",
            "100/100 - 23s - loss: 0.1480 - acc: 0.9420 - val_loss: 0.1044 - val_acc: 0.9600\n",
            "Epoch 41/50\n",
            "100/100 - 21s - loss: 0.1541 - acc: 0.9380 - val_loss: 0.1043 - val_acc: 0.9610\n",
            "Epoch 42/50\n",
            "100/100 - 22s - loss: 0.1571 - acc: 0.9415 - val_loss: 0.1042 - val_acc: 0.9620\n",
            "Epoch 43/50\n",
            "100/100 - 21s - loss: 0.1496 - acc: 0.9385 - val_loss: 0.1043 - val_acc: 0.9610\n",
            "Epoch 44/50\n",
            "100/100 - 22s - loss: 0.1371 - acc: 0.9430 - val_loss: 0.1039 - val_acc: 0.9630\n",
            "Epoch 45/50\n",
            "100/100 - 21s - loss: 0.1503 - acc: 0.9335 - val_loss: 0.1037 - val_acc: 0.9640\n",
            "Epoch 46/50\n",
            "100/100 - 21s - loss: 0.1443 - acc: 0.9395 - val_loss: 0.1033 - val_acc: 0.9620\n",
            "Epoch 47/50\n",
            "100/100 - 22s - loss: 0.1472 - acc: 0.9400 - val_loss: 0.1032 - val_acc: 0.9620\n",
            "Epoch 48/50\n",
            "100/100 - 22s - loss: 0.1400 - acc: 0.9425 - val_loss: 0.1032 - val_acc: 0.9630\n",
            "Epoch 49/50\n",
            "100/100 - 23s - loss: 0.1404 - acc: 0.9450 - val_loss: 0.1027 - val_acc: 0.9640\n",
            "Epoch 50/50\n",
            "100/100 - 22s - loss: 0.1400 - acc: 0.9435 - val_loss: 0.1027 - val_acc: 0.9630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EPGn58ofwq5"
      },
      "source": [
        "We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n",
        "\n",
        "Let's plot the training and validation loss and accuracy to show it conclusively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FtxcKjJfxL9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "4c548ae6-35ee-48db-bf53-a4469143c129"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Retrieve a list of accuracy results on training and validation data\n",
        "# sets for each training epoch\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "# Retrieve a list of list results on training and validation data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-fUIeizakjE"
      },
      "source": [
        "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ANwJCnx7w-"
      },
      "source": [
        "## Clean Up\n",
        "\n",
        "Run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hUmyohAyBzh"
      },
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}